{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.764290755116443,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.035285815102328866,
      "grad_norm": 6.285089492797852,
      "learning_rate": 4.913549752999295e-05,
      "loss": 0.2729,
      "step": 50
    },
    {
      "epoch": 0.07057163020465773,
      "grad_norm": 3.3970751762390137,
      "learning_rate": 4.825335215243472e-05,
      "loss": 0.2233,
      "step": 100
    },
    {
      "epoch": 0.1058574453069866,
      "grad_norm": 1.3573907613754272,
      "learning_rate": 4.73712067748765e-05,
      "loss": 0.1932,
      "step": 150
    },
    {
      "epoch": 0.14114326040931546,
      "grad_norm": 4.418178081512451,
      "learning_rate": 4.648906139731828e-05,
      "loss": 0.1755,
      "step": 200
    },
    {
      "epoch": 0.17642907551164433,
      "grad_norm": 4.950060844421387,
      "learning_rate": 4.560691601976006e-05,
      "loss": 0.168,
      "step": 250
    },
    {
      "epoch": 0.2117148906139732,
      "grad_norm": 0.5080318450927734,
      "learning_rate": 4.4724770642201834e-05,
      "loss": 0.184,
      "step": 300
    },
    {
      "epoch": 0.24700070571630206,
      "grad_norm": 4.728326320648193,
      "learning_rate": 4.3842625264643614e-05,
      "loss": 0.1731,
      "step": 350
    },
    {
      "epoch": 0.2822865208186309,
      "grad_norm": 4.119045734405518,
      "learning_rate": 4.2960479887085394e-05,
      "loss": 0.1895,
      "step": 400
    },
    {
      "epoch": 0.3175723359209598,
      "grad_norm": 2.4922049045562744,
      "learning_rate": 4.2078334509527173e-05,
      "loss": 0.1416,
      "step": 450
    },
    {
      "epoch": 0.35285815102328866,
      "grad_norm": 5.6370110511779785,
      "learning_rate": 4.1196189131968946e-05,
      "loss": 0.1661,
      "step": 500
    },
    {
      "epoch": 0.3881439661256175,
      "grad_norm": 5.340848445892334,
      "learning_rate": 4.031404375441073e-05,
      "loss": 0.1781,
      "step": 550
    },
    {
      "epoch": 0.4234297812279464,
      "grad_norm": 7.784904956817627,
      "learning_rate": 3.9431898376852506e-05,
      "loss": 0.1651,
      "step": 600
    },
    {
      "epoch": 0.45871559633027525,
      "grad_norm": 7.847360610961914,
      "learning_rate": 3.8549752999294286e-05,
      "loss": 0.1346,
      "step": 650
    },
    {
      "epoch": 0.4940014114326041,
      "grad_norm": 6.766743183135986,
      "learning_rate": 3.766760762173606e-05,
      "loss": 0.179,
      "step": 700
    },
    {
      "epoch": 0.529287226534933,
      "grad_norm": 4.309158802032471,
      "learning_rate": 3.6785462244177845e-05,
      "loss": 0.1669,
      "step": 750
    },
    {
      "epoch": 0.5645730416372619,
      "grad_norm": 0.12188404053449631,
      "learning_rate": 3.590331686661962e-05,
      "loss": 0.1421,
      "step": 800
    },
    {
      "epoch": 0.5998588567395907,
      "grad_norm": 1.4807186126708984,
      "learning_rate": 3.50211714890614e-05,
      "loss": 0.1346,
      "step": 850
    },
    {
      "epoch": 0.6351446718419196,
      "grad_norm": 5.384850978851318,
      "learning_rate": 3.413902611150318e-05,
      "loss": 0.1505,
      "step": 900
    },
    {
      "epoch": 0.6704304869442484,
      "grad_norm": 8.721195220947266,
      "learning_rate": 3.325688073394496e-05,
      "loss": 0.1786,
      "step": 950
    },
    {
      "epoch": 0.7057163020465773,
      "grad_norm": 2.4277186393737793,
      "learning_rate": 3.237473535638673e-05,
      "loss": 0.1581,
      "step": 1000
    },
    {
      "epoch": 0.7410021171489062,
      "grad_norm": 5.378254413604736,
      "learning_rate": 3.149258997882851e-05,
      "loss": 0.1264,
      "step": 1050
    },
    {
      "epoch": 0.776287932251235,
      "grad_norm": 0.2566421627998352,
      "learning_rate": 3.061044460127029e-05,
      "loss": 0.1319,
      "step": 1100
    },
    {
      "epoch": 0.8115737473535639,
      "grad_norm": 1.7835793495178223,
      "learning_rate": 2.972829922371207e-05,
      "loss": 0.131,
      "step": 1150
    },
    {
      "epoch": 0.8468595624558928,
      "grad_norm": 0.5057241320610046,
      "learning_rate": 2.8846153846153845e-05,
      "loss": 0.1157,
      "step": 1200
    },
    {
      "epoch": 0.8821453775582216,
      "grad_norm": 0.7367357611656189,
      "learning_rate": 2.7964008468595625e-05,
      "loss": 0.1579,
      "step": 1250
    },
    {
      "epoch": 0.9174311926605505,
      "grad_norm": 0.39000794291496277,
      "learning_rate": 2.70818630910374e-05,
      "loss": 0.1131,
      "step": 1300
    },
    {
      "epoch": 0.9527170077628794,
      "grad_norm": 0.1830175518989563,
      "learning_rate": 2.619971771347918e-05,
      "loss": 0.1315,
      "step": 1350
    },
    {
      "epoch": 0.9880028228652082,
      "grad_norm": 3.5403027534484863,
      "learning_rate": 2.5317572335920958e-05,
      "loss": 0.179,
      "step": 1400
    },
    {
      "epoch": 1.023288637967537,
      "grad_norm": 4.694571495056152,
      "learning_rate": 2.443542695836274e-05,
      "loss": 0.0938,
      "step": 1450
    },
    {
      "epoch": 1.058574453069866,
      "grad_norm": 0.4328680634498596,
      "learning_rate": 2.3553281580804517e-05,
      "loss": 0.0957,
      "step": 1500
    },
    {
      "epoch": 1.0938602681721947,
      "grad_norm": 0.33198878169059753,
      "learning_rate": 2.2671136203246297e-05,
      "loss": 0.0704,
      "step": 1550
    },
    {
      "epoch": 1.1291460832745237,
      "grad_norm": 0.5081918835639954,
      "learning_rate": 2.1788990825688073e-05,
      "loss": 0.1109,
      "step": 1600
    },
    {
      "epoch": 1.1644318983768525,
      "grad_norm": 1.928157925605774,
      "learning_rate": 2.0906845448129853e-05,
      "loss": 0.0972,
      "step": 1650
    },
    {
      "epoch": 1.1997177134791814,
      "grad_norm": 4.757661819458008,
      "learning_rate": 2.0024700070571632e-05,
      "loss": 0.0925,
      "step": 1700
    },
    {
      "epoch": 1.2350035285815102,
      "grad_norm": 0.4496907591819763,
      "learning_rate": 1.914255469301341e-05,
      "loss": 0.0751,
      "step": 1750
    },
    {
      "epoch": 1.2702893436838392,
      "grad_norm": 0.1016286239027977,
      "learning_rate": 1.826040931545519e-05,
      "loss": 0.0588,
      "step": 1800
    },
    {
      "epoch": 1.305575158786168,
      "grad_norm": 0.1479169875383377,
      "learning_rate": 1.7378263937896965e-05,
      "loss": 0.0881,
      "step": 1850
    },
    {
      "epoch": 1.340860973888497,
      "grad_norm": 0.9535192847251892,
      "learning_rate": 1.6496118560338744e-05,
      "loss": 0.0858,
      "step": 1900
    },
    {
      "epoch": 1.3761467889908257,
      "grad_norm": 0.09792254120111465,
      "learning_rate": 1.561397318278052e-05,
      "loss": 0.08,
      "step": 1950
    },
    {
      "epoch": 1.4114326040931546,
      "grad_norm": 0.0991850420832634,
      "learning_rate": 1.47318278052223e-05,
      "loss": 0.072,
      "step": 2000
    },
    {
      "epoch": 1.4467184191954834,
      "grad_norm": 2.6938719749450684,
      "learning_rate": 1.3849682427664079e-05,
      "loss": 0.1095,
      "step": 2050
    },
    {
      "epoch": 1.4820042342978124,
      "grad_norm": 0.14465557038784027,
      "learning_rate": 1.2967537050105858e-05,
      "loss": 0.0679,
      "step": 2100
    },
    {
      "epoch": 1.5172900494001411,
      "grad_norm": 2.46441650390625,
      "learning_rate": 1.2085391672547638e-05,
      "loss": 0.1,
      "step": 2150
    },
    {
      "epoch": 1.55257586450247,
      "grad_norm": 0.2899460196495056,
      "learning_rate": 1.1203246294989416e-05,
      "loss": 0.0815,
      "step": 2200
    },
    {
      "epoch": 1.5878616796047988,
      "grad_norm": 0.11416691541671753,
      "learning_rate": 1.0321100917431194e-05,
      "loss": 0.072,
      "step": 2250
    },
    {
      "epoch": 1.6231474947071276,
      "grad_norm": 2.0816762447357178,
      "learning_rate": 9.438955539872972e-06,
      "loss": 0.087,
      "step": 2300
    },
    {
      "epoch": 1.6584333098094566,
      "grad_norm": 3.0291988849639893,
      "learning_rate": 8.55681016231475e-06,
      "loss": 0.0951,
      "step": 2350
    },
    {
      "epoch": 1.6937191249117856,
      "grad_norm": 3.771616220474243,
      "learning_rate": 7.674664784756528e-06,
      "loss": 0.0575,
      "step": 2400
    },
    {
      "epoch": 1.7290049400141143,
      "grad_norm": 0.09192848205566406,
      "learning_rate": 6.792519407198307e-06,
      "loss": 0.0733,
      "step": 2450
    },
    {
      "epoch": 1.764290755116443,
      "grad_norm": 0.2038218230009079,
      "learning_rate": 5.910374029640085e-06,
      "loss": 0.0565,
      "step": 2500
    }
  ],
  "logging_steps": 50,
  "max_steps": 2834,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2630650109253120.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
